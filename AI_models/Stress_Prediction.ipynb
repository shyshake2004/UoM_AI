{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d772ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1507106979.py, line 157)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 157\u001b[1;36m\u001b[0m\n\u001b[1;33m    best_name = max(results.keys(), key=lambda k: (results[k]['test_score'] if results[k]['test_score'] is not None else)\u001b[0m\n\u001b[1;37m                                                                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 1) Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# %%\n",
    "# 2) Config\n",
    "CSV_PATH = r\"C:\\Users\\ASUS\\Downloads\\archive (1)\\Sleep_health_and_lifestyle_dataset.csv\"\n",
    "OUT_MODEL_PATH = r\"C:\\Users\\ASUS\\Downloads\\archive (1)\\best_model.pkl\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# %%\n",
    "# 3) Load data\n",
    "print(\"Loading:\", CSV_PATH)\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Quick preview\n",
    "print('\\n--- Head ---')\n",
    "print(df.head())\n",
    "print('\\n--- Dtypes ---')\n",
    "print(df.dtypes)\n",
    "# %%\n",
    "# 4) Quick EDA\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isnull().sum())\n",
    "print('\\nBasic description (numeric):')\n",
    "print(df.describe().T)\n",
    "\n",
    "# Optional: show simple plots\n",
    "try:\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    if len(numeric_cols) > 0:\n",
    "        df[numeric_cols].hist(figsize=(12, 8))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print('Plotting failed:', e)\n",
    "\n",
    "# %%\n",
    "# 5) Auto-select target column\n",
    "# Preference: any column containing 'sleep' (case-insensitive), otherwise last column\n",
    "sleep_cols = [c for c in df.columns if 'sleep' in c.lower()]\n",
    "if len(sleep_cols) > 0:\n",
    "    target_col = sleep_cols[0]\n",
    "else:\n",
    "    target_col = df.columns[-1]\n",
    "\n",
    "print('\\nSelected target column for modeling:', target_col)\n",
    "\n",
    "# %%\n",
    "# 6) Determine task type\n",
    "n_unique = df[target_col].nunique(dropna=True)\n",
    "is_classification = False\n",
    "if df[target_col].dtype == 'object' or n_unique <= 10:\n",
    "    is_classification = True\n",
    "\n",
    "print('Inferred task:', 'classification' if is_classification else 'regression')\n",
    "\n",
    "# %%\n",
    "# 7) Prepare features and labels\n",
    "X = df.drop(columns=[target_col]).copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Drop columns that are constant\n",
    "const_cols = [c for c in X.columns if X[c].nunique(dropna=True) <= 1]\n",
    "if const_cols:\n",
    "    print('Dropping constant columns:', const_cols)\n",
    "    X.drop(columns=const_cols, inplace=True)\n",
    "\n",
    "num_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "print(f'Numeric cols: {num_cols}\\nCategorical cols: {cat_cols}')\n",
    "\n",
    "# %%\n",
    "# 8) Build preprocessing pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='__MISSING__')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "# %%\n",
    "# 9) Define candidate models\n",
    "if is_classification:\n",
    "    candidates = {\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE),\n",
    "        'GradientBoosting': GradientBoostingClassifier(n_estimators=200, random_state=RANDOM_STATE),\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000)\n",
    "    }\n",
    "else:\n",
    "    candidates = {\n",
    "        'RandomForestRegressor': RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE),\n",
    "        'GradientBoostingRegressor': GradientBoostingRegressor(n_estimators=200, random_state=RANDOM_STATE),\n",
    "        'LinearRegression': LinearRegression()\n",
    "    }\n",
    "\n",
    "# %%\n",
    "# 10) Train / CV / Evaluate\n",
    "# If classification and >1 unique values, stratify\n",
    "stratify = y if (is_classification and n_unique>1) else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=stratify)\n",
    "results = {}\n",
    "for name, model in candidates.items():\n",
    "    print('\\nTraining', name)\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), ('model', model)])\n",
    "    # cross-val\n",
    "    try:\n",
    "        if is_classification:\n",
    "            scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "            cv_mean = np.mean(scores)\n",
    "            print(f'  CV accuracy (5-fold): {cv_mean:.4f} (std {np.std(scores):.4f})')\n",
    "        else:\n",
    "            scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring='r2')\n",
    "            cv_mean = np.mean(scores)\n",
    "            print(f'  CV R2 (5-fold): {cv_mean:.4f} (std {np.std(scores):.4f})')\n",
    "    except Exception as e:\n",
    "        print('  Cross-val failed:', e)\n",
    "        cv_mean = None\n",
    "    # fit and test\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    if is_classification:\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print('  Test accuracy:', acc)\n",
    "        print('  Classification report:\\n', classification_report(y_test, y_pred))\n",
    "        results[name] = {'cv_score': cv_mean, 'test_score': acc, 'pipeline': pipe}\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        print('  Test R2:', r2)\n",
    "        print('  Test MAE:', mae)\n",
    "        results[name] = {'cv_score': cv_mean, 'test_score': r2, 'pipeline': pipe}\n",
    "\n",
    "# %%\n",
    "# 11) Choose best model and save it\n",
    "best_name = max(results.keys(), key=lambda k: (results[k]['test_score'] if results[k]['test_score'] is not None else)\n",
    "best = results[best_name]['pipeline']\n",
    "print('\\nBest model:', best_name)\n",
    "joblib.dump(best, OUT_MODEL_PATH)\n",
    "print('Saved best model to', OUT_MODEL_PATH)\n",
    "\n",
    "# %%\n",
    "# 12) Save a simple CSV report\n",
    "report = []\n",
    "for k, v in results.items():\n",
    "    report.append({'model': k, 'cv_score': v['cv_score'], 'test_score': v['test_score']})\n",
    "report_df = pd.DataFrame(report).sort_values('test_score', ascending=False)\n",
    "report_df.to_csv(r'C:\\Users\\ASUS\\Downloads\\archive (1)/model_report.csv', index=False)\n",
    "print('Saved model_report.csv to /mnt/data/model_report.csv')\n",
    "\n",
    "# %%\n",
    "# 13) How to load the saved model (example)\n",
    "print('\\nExample of loading the saved model:')\n",
    "print(\"import joblib\\nmodel = joblib.load('/mnt/data/best_model.pkl')\\n# then model.predict(X_new)\")\n",
    "\n",
    "# %%\n",
    "# END\n",
    "print('\\nNotebook finished. Modify the target_col and candidate models if you want to experiment further.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6904927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
