{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4848d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "\n",
    "# ============================================================\n",
    "# üìÇ LOAD DATA\n",
    "# ============================================================\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\Downloads\\archive\\Housing.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# ============================================================\n",
    "# üîç BASIC INFO\n",
    "# ============================================================\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe())\n",
    "\n",
    "# ============================================================\n",
    "# üß† PREPROCESSING\n",
    "# ============================================================\n",
    "\n",
    "# Convert binary yes/no columns to numeric\n",
    "binary_cols = ['mainroad','guestroom','basement','hotwaterheating','airconditioning','prefarea']\n",
    "for col in binary_cols:\n",
    "    df[col] = df[col].map({'yes':1, 'no':0})\n",
    "\n",
    "# One-hot encode furnishingstatus\n",
    "df = pd.get_dummies(df, columns=['furnishingstatus'], drop_first=True)\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=['price'])\n",
    "y = df['price']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Numeric columns to scale\n",
    "numeric_cols = ['area','bedrooms','bathrooms','stories','parking']\n",
    "\n",
    "# Standard scaling for numeric columns\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_cols)], remainder='passthrough')\n",
    "\n",
    "# ============================================================\n",
    "# üß© MODEL SETUP\n",
    "# ============================================================\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Linear Regression\n",
    "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', LinearRegression())])\n",
    "\n",
    "# XGBoost (fallback: RandomForest if XGBoost not available)\n",
    "try:\n",
    "    xgb_model = XGBRegressor(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "except:\n",
    "    xgb_model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('model', xgb_model)])\n",
    "\n",
    "# ============================================================\n",
    "# üèãÔ∏è‚Äç‚ôÇÔ∏è TRAIN MODELS\n",
    "# ============================================================\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ============================================================\n",
    "# üìä EVALUATION FUNCTION\n",
    "# ============================================================\n",
    "def evaluate_model(name, pipeline, X_tr, X_te, y_tr, y_te):\n",
    "    y_pred = pipeline.predict(X_te)\n",
    "    rmse = mean_squared_error(y_te, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_te, y_pred)\n",
    "    r2 = r2_score(y_te, y_pred)\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_rmse = np.sqrt(-cross_val_score(pipeline, X_tr, y_tr, \n",
    "                                       scoring='neg_mean_squared_error', cv=cv))\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE : {mae:.2f}\")\n",
    "    print(f\"Test R¬≤  : {r2:.4f}\")\n",
    "    print(f\"CV RMSE (mean ¬± std): {cv_rmse.mean():.2f} ¬± {cv_rmse.std():.2f}\")\n",
    "    return rmse\n",
    "\n",
    "rmse_lr = evaluate_model(\"Linear Regression\", lr_pipeline, X_train, X_test, y_train, y_test)\n",
    "rmse_xgb = evaluate_model(\"XGBoost\", xgb_pipeline, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# ============================================================\n",
    "# üèÜ CHOOSE BEST MODEL\n",
    "# ============================================================\n",
    "best_pipeline = lr_pipeline if rmse_lr < rmse_xgb else xgb_pipeline\n",
    "print(\"\\n‚úÖ Best Model:\", \"Linear Regression\" if rmse_lr < rmse_xgb else \"XGBoost\")\n",
    "\n",
    "# ============================================================\n",
    "# üåü FEATURE IMPORTANCES / COEFFICIENTS\n",
    "# ============================================================\n",
    "numeric_cols = ['area','bedrooms','bathrooms','stories','parking']\n",
    "other_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "pipeline_feature_names = numeric_cols + other_cols\n",
    "\n",
    "model = best_pipeline.named_steps['model']\n",
    "\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    fi = pd.Series(model.feature_importances_, index=pipeline_feature_names).sort_values(ascending=False)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    fi.head(10).plot(kind='bar')\n",
    "    plt.title(\"Top 10 Feature Importances (XGBoost)\")\n",
    "    plt.show()\n",
    "elif hasattr(model, 'coef_'):\n",
    "    coef = pd.Series(model.coef_, index=pipeline_feature_names).sort_values(key=abs, ascending=False)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    coef.head(10).plot(kind='bar')\n",
    "    plt.title(\"Top 10 Coefficients (Linear Regression)\")\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# üíæ SAVE MODEL\n",
    "# ============================================================\n",
    "with open(\"best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_pipeline, f)\n",
    "\n",
    "print(\"\\nüíæ Model saved as best_model.pkl\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
